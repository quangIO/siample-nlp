{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from typing import List, Dict, Tuple\n",
    "import os\n",
    "import itertools\n",
    "\n",
    "TEST_WORDS_FILE: str = os.getenv(\"TEST_WORDS_FILE\", \"WSJ_23.words\")\n",
    "\n",
    "def glance(d, _f: int = 0, _t: int=3):\n",
    "    return dict(itertools.islice(d.items(), _f, _t))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Handling OOV\n",
    "* has digit?\n",
    "* is capitalized?\n",
    "* has symbol like '-' or '/'?\n",
    "* common suffixes\n",
    "* common prefixes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "outputs": [
    {
     "data": {
      "text/plain": "{'In': [('IN', 0.9972283813747228),\n  ('NNP', 0.0016629711751662971),\n  ('RB', 0.0005543237250554324),\n  ('RBR', 0.0005543237250554324)],\n 'an': [(',', 0.00030950170225936243), ('DT', 0.9996904982977406)],\n 'Oct.': [('NN', 0.003003003003003003), ('NNP', 0.996996996996997)]}"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 176
    }
   ],
   "source": [
    "with open(\"merged.pos\") as f:\n",
    "    lines: List[str] = [l for l in f if l != \"\\n\"]\n",
    "    record_length: int = len(lines)\n",
    "    words: List[str] = [\"\"] * record_length\n",
    "    tags: List[str] = [\"\"] * record_length\n",
    "    for i in range(record_length):\n",
    "        words[i], tags[i] = lines[i].split()\n",
    "\n",
    "def classify(w: str):\n",
    "    if any(c.isdigit() for c in w):\n",
    "        return \"U_CD\"\n",
    "    if w[0].isupper():\n",
    "        return \"U_up\"\n",
    "    if \"-\" in w:\n",
    "        return \"U_hyp\"\n",
    "    if \"/\" in w:\n",
    "        return \"U_slash\"\n",
    "    suffixes: List[str] = [\"ly\", \"ed\", \"ble\", \"ous\", \"s\", \"ing\", \n",
    "                \"ion\", \"ism\", \"ist\", \"al\", \"um\", \"er\", \n",
    "                \"es\", \"ent\", \"ize\", \"ful\", \"ive\"]\n",
    "    for s in suffixes:\n",
    "        if w.lower().endswith(s):\n",
    "            return \"U_\" + s\n",
    "    prefixes: List[str] = [\"extra\", \"hetero\", \"homo\", \"ir\", \"in\", \n",
    "                \"im\", \"macro\", \"micro\", \"non\", \"omni\"]\n",
    "    for p in prefixes:\n",
    "        if w.lower().startswith(p):\n",
    "            return \"U_\" + p\n",
    "    if len(w) == 1:\n",
    "        return \"U_sym\"\n",
    "    return \"U_Unknown\"\n",
    "\n",
    "from collections import Counter\n",
    "words_occur: Dict[str, int] = Counter(words)\n",
    "for i in range(record_length):\n",
    "    if words_occur[words[i]] == 1:\n",
    "        words[i] = classify(words[i])\n",
    "\n",
    "tag_tag_e: Dict[str, Dict[str, float]] = {}\n",
    "word_tag_e: Dict[str, Dict[str, float]] = {}\n",
    "tag_tag: Dict[str, List[Tuple[str, float]]] = {}\n",
    "word_tag: Dict[str, List[Tuple[str, float]]] = {}\n",
    "for i in range(record_length - 1):\n",
    "    from_tag: str = tags[i]\n",
    "    to_tag: str = tags[i + 1]\n",
    "    if not tag_tag_e.get(from_tag): tag_tag_e[from_tag] = {}\n",
    "    if not tag_tag_e[from_tag].get(to_tag): tag_tag_e[from_tag][to_tag] = 0\n",
    "    tag_tag_e[from_tag][to_tag] += 1\n",
    "    \n",
    "    from_word: str = words[i]\n",
    "    if not word_tag_e.get(from_word): word_tag_e[from_word] = {}\n",
    "    if not word_tag_e[from_word].get(from_tag): word_tag_e[from_word][from_tag] = 0\n",
    "    word_tag_e[from_word][from_tag] += 1\n",
    "\n",
    "for key in tag_tag_e.keys():\n",
    "    to_dict_tag: Dict[str, float] = tag_tag_e[key]\n",
    "    total = sum(to_dict_tag.values())\n",
    "    for in_key in to_dict_tag.keys(): to_dict_tag[in_key] /= total\n",
    "    tag_list = sorted(to_dict_tag.items(), key = lambda x: x[0])\n",
    "    tag_tag[key] = tag_list\n",
    "\n",
    "for key in word_tag_e.keys():\n",
    "    to_dict_word: Dict[str, float] = word_tag_e[key]\n",
    "    total = sum(to_dict_word.values())\n",
    "    for in_key in to_dict_word.keys(): to_dict_word[in_key] /= total\n",
    "    word_list = sorted(to_dict_word.items(), key = lambda x: x[0])\n",
    "    word_tag[key] = word_list\n",
    "\n",
    "glance(word_tag)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Main algorithm\n",
    "Normal HMM, it only cares about the previous tag."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "outputs": [],
   "source": [
    "with open(TEST_WORDS_FILE) as f:\n",
    "    test_words: List[str] = [line.rstrip() for line in f]\n",
    "\n",
    "test_length = len(test_words)\n",
    "\n",
    "ans: List[str] = [\"\"] * test_length\n",
    "out: List[str] = [\"\"] * test_length\n",
    "for i in range(test_length):\n",
    "    current_word: str = test_words[i]\n",
    "    if current_word == \"\":\n",
    "        out[i] = out[i - 1]\n",
    "        ans[i] = \"\"\n",
    "        continue\n",
    "    if current_word not in word_tag_e:\n",
    "        current_word = classify(current_word)\n",
    "    transitions = tag_tag[\".\"] if not i else tag_tag[out[i - 1]]\n",
    "    emissions = word_tag.get(current_word, 0)\n",
    "    if not emissions: \n",
    "        ans[i] = out[i] = \"NNP\"\n",
    "        # out[i] = [for e in emissions]\n",
    "        continue\n",
    "    max_p: float = 0\n",
    "    current_p: float = 0\n",
    "    j: int = 0\n",
    "    k: int = 0\n",
    "    while j < len(transitions) and k < len(emissions):\n",
    "        transition_tag, emission_tag = transitions[j][0], emissions[k][0]\n",
    "        if emission_tag == transition_tag:\n",
    "            current_p = transitions[j][1] * emissions[k][1]\n",
    "            if current_p > max_p:\n",
    "                out[i] = transition_tag\n",
    "                max_p = current_p\n",
    "            j += 1\n",
    "            k += 1\n",
    "        elif transition_tag > emission_tag: k += 1\n",
    "        else: j += 1\n",
    "    if out[i]==\"\":\n",
    "        out[i] = \"NNP\"\n",
    "        out[i] = max(emissions,key=lambda x: x[1])[0]  \n",
    "    ans[i] = out[i]\n",
    "lst_out = [(w + \"\\t\" + t) if len(t) else \"\" for (w, t) in zip(test_words, ans)]\n",
    "with open(\"submission.pos\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(lst_out) + \"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}